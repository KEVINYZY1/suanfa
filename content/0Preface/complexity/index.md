---
title: 计算可解性
prev: /0preface
next: /1链表
weight: 5
---

在设计算法的时候，我们需要考虑这样一个问题--随着输入规模的增长，算法的时间成本和所占的空间数量会发生什么样的变化。
在不同的应用场景下，我们会遇到不同的问题。所以没有最好的算法，只有最适合的算法。

### 什么是有效率的算法
一个算法是否有效率，是和其输入样例密不可分的。假设我们需要设计一个排序算法，这个待排序的序列可能基本已经排序了，也可能完全处于混乱状态，同一个算法可能会有明显的效率差。我们需要一个关于有效的定义，它是一个与输入实例无关的定义。

### 多项式时间
自然界中组合问题的搜索空间往往随输入规模成指数倍增长。就是说,如果输入规模加1，蛮力搜索的时间复杂度将成倍增加。假设我们有一个算法，使得当我们的输入规模为N时，其运行时间不超过 `$ cN^d $` ，我们就说这个算法是一个多项式时间的算法。我们可以提出这样一个朴素的定义：**如果一个算法有多项式运行时间，它就是有效的**

### 如何更好地量化算法效率
我们想以一种更简单的方式来表达运行时间。比如 `$ 1.6n^2 + 3n + 12 $` ,随着输入规模的增大，低项对运行时间的影响会变得很低。而系数也不受输入规模的影响，所以我们可以用 `$ n^2 $` 来表示算法的时间复杂度。

这里我们引入 **O(.)** 表达式来表示运行时间的上界。假设一个算法的最坏运行时间为`$ T(n) $`,假设存在一个函数`$f(n)$`，满足当n足够大时`$T(n) \leq c*f(n)$` ，其中c为常数，那么我们就说f为T的上界，记作 `$ T(n) = O(f(n)) $`。

比如一个算法的运算时间的上界为`$T(n) = 100n^2 + 9999n + 2$`，我们可以用`$O(n^2)$`来表示其时间复杂度。

除了上界，我们还可以分析一个算法运行 **下界** 。记作`$T(n)=\Omega(f(n))$`,对于 `$T(n) = 100n^2 + 9999n + 2$`，我们也可以用`$\Omega(n^2)$`来表示其时间复杂度。

我们注意到上面的例子中`$T(n)$`既是`$O(n^2)$`也是`$\Omega(n^2)$`，这时候我们可以引入`$\Theta()$`表达式来表示"紧界"。如果一个函数`$T(n)$`既是`$O(f(n))$`又是`$\Omega(f(n))$`我们就说`$T(n)=\Theta(f(n))$`

## 常见时间复杂度
时间复杂度 | 例子
--- | ---
`$O(logn)$` | 二分搜索
`$O(n)$` | 计算数组中最大数
`$O(nlogn)$` | 归并排序
`$O(n^2)$` | 找最近邻点的蛮力算法
超出多项式时间 | 独立集问题
